[
  {
    "user_id": "cohort_20383_user_385374",
    "user_name": "Pavel Shtykovskiy",
    "goal_text": "Gain practical, in-the-trenches experience from industry experts on training and deploying production-ready agents. Take a break from reading RL papers and code instead :)",
    "created_at": "2025-06-16T14:09:06.742799Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_649515",
    "user_name": "Kevin Wang",
    "goal_text": "I have two main goals for this course:\n\n*   I want to soak up all there is to learn from Will and Kyle about RL x LLMs; I'd like to use this course to really penetrate into the weeds of this world.\n    \n*   I want to get a solid grasp of the landscape of building and productionizing agentic systems: the current frontier, the challenges, the bottlenecks, as well as how RL interplays with all of it.",
    "created_at": "2025-06-16T14:22:09.347275Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_620493",
    "user_name": "Morteza",
    "goal_text": "1.  How to design and implement safe Agents.\n    \n2.  When the RL is needed in creating Agents and What is the most efficient way of the Agent fine tuning using RL.\n    \n3.  How to gather (or synth) the data for Agent training.",
    "created_at": "2025-06-16T15:47:34.211721Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647925",
    "user_name": "Jacob Milleville",
    "goal_text": "1\\. Gain familiarity with custom agent frameworks and related best practices - I work with agents now but I feel like there is room for improvement in the abstractions and tools I use for future projects.  \n2\\. Do some RL - I want to learn as many practical components of doing RL as possible. Excited to have support getting through some of the setup slog that has previously discouraged me from experimenting here in the past.  \n3\\. Learn more about how you're thinking on MCP/A2A - I hear lots of wild stuff being thrown around about these protocols constantly, and am personally a little underwhelmed by them at the technical level especially re: the problems they don't solve.",
    "created_at": "2025-06-16T15:52:30.10191Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647693",
    "user_name": "Tanush Jagdish",
    "goal_text": "I'm the founder of Olito Labs. We build AI tools that help banks and credit unions manage regulatory and supervisory issues.\n\nThrough this course, I want to:  \n\n1.  **Train a small GRPO-fine-tuned model** that beats a baseline GPT-4 prompt on a banking regulation test set by >25% composite reward (accuracy + relevance).\n    \n2.  **Stand up a custom MCP server** with auth and logging, document its design, and demo secure tool calls live during the final week’s office hours.\n    \n3.  **Implement and open-source an eval script** (rule-based + LLM-judge) to score banking regulation-specific answers and generate rewards\n    \n\nAll of this put together, the ultimate goal is to deliver a working prototype that (a) uses MCP to call external tools (FDIC reg search) and (b) completes a full ReAct reasoning loop with output that can be evaluated",
    "created_at": "2025-06-16T16:00:04.775906Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_648666",
    "user_name": "AJ Ade",
    "goal_text": "To be able to take any problem, decompose it into its constituent parts and apply RL as needed or any Agentic framework or MCP tools",
    "created_at": "2025-06-16T16:15:50.231304Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647482",
    "user_name": "Ben Perlmutter",
    "goal_text": "I would like to learn more about RL and building reliable AI agents.",
    "created_at": "2025-06-16T16:43:39.198449Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_646942",
    "user_name": "Surender Suresh Kumar",
    "goal_text": "Understand the practical challenges involved in training agents with RL, in particular which sort of reward models work well in which contexts",
    "created_at": "2025-06-16T16:44:55.791255Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_665118",
    "user_name": "William Huang",
    "goal_text": "Build a knowledge foundation for bringing MCP/agent engineering into our engineering org",
    "created_at": "2025-06-16T16:48:13.518917Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_378036",
    "user_name": "Kazuki Inamura",
    "goal_text": "*   Deepen my understanding of the key leverage points in MCP, drawing on insights from the lectures while valuing the informal, practice-driven intuitions of working professionals.\n    \n*   Reach a level where I can confidently deliver AI agents as production-ready outputs in my day-to-day role as an AI engineer—on par with the confidence I already have when shipping an ML model, its code, and its evaluation.\n    \n*   Learn how and when to choose RL, in particular GRPO, for fine-tuning local LLMs, especially exploring its potential in combination with an LLM-based reward model that provides \"soft-verifiable\" feedback.\n    \n\nBy the last week, I'll try to ship an AI agent prototype to internal staging environment in my company (it'll be something like a RAG agent or an LLM-as-a-judge Evaluator agent.)",
    "created_at": "2025-06-16T16:59:24.175244Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_646458",
    "user_name": "Kevin Davis",
    "goal_text": "Goals:  \n  \nImprove understanding of MCP architecture and use cases. When to use/when not to, etc  \nGet a hands-on understanding of SoTA for using RL on open models. ART-E email example is an interesting starting point, but valuable real world problems seem way too complex for current models, both from a capabilities and evaluation perspective.  \nBuild and evaluate powerful agents that hopefully can be applied to problems in my domain!",
    "created_at": "2025-06-16T17:09:04.734848Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_648699",
    "user_name": "Nick  Gideo",
    "goal_text": "Gain proficiency with building and evaluating agents.",
    "created_at": "2025-06-16T17:14:21.102003Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_648755",
    "user_name": "Satya Krishna Gorti",
    "goal_text": "Understand the practical aspects of RL in training LMs and building reasoning models.",
    "created_at": "2025-06-16T17:35:18.180995Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_640587",
    "user_name": "Jay Wengrow",
    "goal_text": "To gain expertise with agents and MCP",
    "created_at": "2025-06-16T18:41:39.654341Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_662398",
    "user_name": "James",
    "goal_text": "What kind of scaffolding do \"agents\" do best with? How much does this scaffolding change over time? When can you use a smaller model distilled from a larger, and what percentage of SFT on the outputs of the larger model vs RL with the smaller is right? What kinds of tasks benefit from scaffolding, and which continue to suck?",
    "created_at": "2025-06-16T19:20:52.244121Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_646845",
    "user_name": "Louis Santoro",
    "goal_text": "Build a prototype of a multiagent system for formal proof verification in Lean 4. Possibly enhance the interpretative side of a research pipeline and start to elaborate a writing pipeline.",
    "created_at": "2025-06-16T20:12:11.039153Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_233409",
    "user_name": "Sumita Palanisamy ",
    "goal_text": "To get hands on experience in agents and mcp!",
    "created_at": "2025-06-16T20:54:29.810088Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_359502",
    "user_name": "Chris Hugentobler",
    "goal_text": "To learn how to go from evaluations to a feedback loop to make AI applications better.",
    "created_at": "2025-06-16T22:16:55.215823Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_665200",
    "user_name": "Kachi Odoemene",
    "goal_text": "Hands-on refresher on RL. Looking forward to building and deploying RL agents.",
    "created_at": "2025-06-17T01:01:33.573937Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647376",
    "user_name": "Eric Gradman",
    "goal_text": "I've now developed several agents for personal and professional use, and my facility with the tools is increasing with each iteration. I want to take it up a notch, and feel as proficient with LLMs as I feel with the tools I've used for years.\n\nI'm particularly excited to learn about how to apply RL to my work, because I sense RL will be integral to making LLMs feel like more than just \"fancy autocomplete!\"",
    "created_at": "2025-06-17T01:04:20.145728Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_402175",
    "user_name": "Ipsita Mohanty",
    "goal_text": "Learn something new!",
    "created_at": "2025-06-17T02:17:35.32304Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647597",
    "user_name": "Jake Nations",
    "goal_text": "My goals for the course are learning more about RL and applying it to agents.",
    "created_at": "2025-06-17T03:40:35.238341Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_337796",
    "user_name": "Sairam Chitreddy",
    "goal_text": "Get a foundation about RLVR and learn how to apply it to my use cases",
    "created_at": "2025-06-17T04:02:09.466265Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_495458",
    "user_name": "Mars",
    "goal_text": "Identify a practical use case where an agent would be more effective than static code. Build the agent. Evaluate the agent. Fine-tune it using RL. Re-eval. Success.\n\nI’ve some exp in building an agentic RAG, but want to deep dive into fundamental concepts and gain expertise.",
    "created_at": "2025-06-17T04:36:35.213616Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_663062",
    "user_name": "Pratyush R Tiwari",
    "goal_text": "Be able to do reinforcement fine-tuning for problems I care about on small models  \n  \nBe able to improve on papers like this with more compute [https://socialdeductionllm.github.io/](https://socialdeductionllm.github.io/)",
    "created_at": "2025-06-17T04:57:56.485329Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_660142",
    "user_name": "Michał Barrington",
    "goal_text": "Goal(s):\n\n1) Master the art of building smart(er) agents\n\n2) Become more accustomed with the concept of MCP and start utilising it more\n\n3) Get hands-on experience with RL, beyond pure theory\n\n4) Understand best practices in the field\n\nPersonal project I'd like to improve:\n\nTake the gained knowledge and Implement an agent as a 'home assistant' mainly to control my smart-lights env lol (siri is extremely limited and I refuse to pay for additional hardware to unlock the full potential if the API is freely available).\n\nChange my current approach of (struggling to implement a) wake-word detection model -> transcribe -> detect command -> use relevant func\n\ninto\n\nvoice2text -> agent -> tool usage",
    "created_at": "2025-06-16T09:48:49.457065Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647076",
    "user_name": "Denis Wambold",
    "goal_text": "Learn more about Agents, MCP, best practices and get deep into RL and the theoretical part behind it.",
    "created_at": "2025-06-16T09:58:15.589444Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_648206",
    "user_name": "Victor Adafinoaiei ",
    "goal_text": "Learn and apply RL model fine tuning for a PoC and expand.",
    "created_at": "2025-06-16T10:47:58.538358Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_664556",
    "user_name": "Julian - Thomas Erdoedy",
    "goal_text": "to learn practical implementations of developing performant agent-based systems, products, or services, with real-world examples.\n\nto have the opportunity to exchange with like-minds, perhaps engage in mutual projects and learn as much as possible from the frontier of RL-optimised agentic systems.",
    "created_at": "2025-06-16T11:47:22.845452Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_646892",
    "user_name": "Antonin Couturier",
    "goal_text": "Have enough understanding of MCP and GRPO to start building with those in prod",
    "created_at": "2025-06-16T12:31:35.928366Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_647712",
    "user_name": "Isfandiyar Shaheen",
    "goal_text": "Use reinforcement learning in an MCP Client-Server combo I've made to improve both retrieval and synthesis",
    "created_at": "2025-06-16T12:31:53.766062Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_649067",
    "user_name": "Ilija Lichkovski",
    "goal_text": "*   Learn to hill-climb narrow domains with agentic RL (medical diagnoses, for instance)\n    \n*   Learn from folks about their ideas!",
    "created_at": "2025-06-16T12:34:52.440895Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_24012",
    "user_name": "Adi Pradhan",
    "goal_text": "I'm building [Socratify](https://www.socratify.com/), an [AI coach for professional upskilling](https://www.socratify.com/) in an AI native world with a focus on critical thinking and communication skills  \n  \nI want to get to the next echelon of performance on various tasks and believe agentic workflows + some RL will be massively impactful",
    "created_at": "2025-06-16T12:59:43.581805Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_665546",
    "user_name": "Harry Jackson",
    "goal_text": "Fine-tune a small reasoning model to perform some non-trivial task well.",
    "created_at": "2025-06-16T13:25:26.87028Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_651280",
    "user_name": "Troy Prebenda",
    "goal_text": "Learn about best practices for MCP + RL in AI-based apps.",
    "created_at": "2025-06-16T13:57:50.915726Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_601555",
    "user_name": "Hendrik Reh",
    "goal_text": "**My goals for this course**\n\n1.  **Ship an agentic proof-of-concept**\n    \n2.  **Master the nuts-and-bolts of MCP + RL**\n    \n3.  **Harvest battle-tested patterns from the cohort**\n    \n4.  **Spark future collabs**",
    "created_at": "2025-06-14T07:37:40.202812Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_661301",
    "user_name": "Vishal Goklani",
    "goal_text": "To train an AI from scratch (no external libraries like TRL etc) that properly uses reinforcement learning to solve puzzles. The emphasis here is \"from scratch\" and working through all the finer details. I went to school in physics/math, but I find that I'm missing a few pieces when reading through the literature. Thanks!",
    "created_at": "2025-06-15T12:49:11.703997Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_373752",
    "user_name": "Eddy Atkins",
    "goal_text": "I want help being able to define business tasks in the context of verifiable RL/Agentic systems",
    "created_at": "2025-06-15T14:36:25.350794Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_321525",
    "user_name": "Swetha Ganesan",
    "goal_text": "Learn about MCP and RL and how to bring those into my product.\n\nLearn about the gotchas and best practices to support enterprises before building",
    "created_at": "2025-06-15T15:46:47.851197Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_370261",
    "user_name": "Anoop",
    "goal_text": "1.  bootstrap on agentic RL via hands on\n    \n2.  tradeoffs - when and when not to use agentic RL\n    \n3.  make connections",
    "created_at": "2025-06-15T16:04:33.431367Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_261267",
    "user_name": "Rishad Bharucha",
    "goal_text": "Ship an RL agent system and MCP.",
    "created_at": "2025-06-15T16:54:29.969436Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_649681",
    "user_name": "Arihant Jain",
    "goal_text": "**Ship an agentic poc. Learn about MCP + RL and real world applications**",
    "created_at": "2025-06-15T17:17:41.25692Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_664017",
    "user_name": "Jhordan",
    "goal_text": "build a real time online learning system with custom metrics and rewards",
    "created_at": "2025-06-15T17:41:21.354116Z",
    "channel_name": "Reflect: Goals"
  },
  {
    "user_id": "cohort_20383_user_648248",
    "user_name": "sam",
    "goal_text": "I want to refresh myself on AI concepts and prepare for AI engineering interviews, while learning helpful cutting edge science.",
    "created_at": "2025-06-15T17:48:16.232067Z",
    "channel_name": "Reflect: Goals"
  }
]